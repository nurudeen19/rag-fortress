# ==============================================================================
# APPLICATION
# ==============================================================================
APP_NAME=RAG Fortress
APP_DESCRIPTION=Secure document intelligence platform for teams
APP_VERSION=1.1.0
DEBUG=True
ENVIRONMENT=development
HOST=0.0.0.0
PORT=8000
DEMO_MODE=false
FRONTEND_URL=http://localhost:3000

# ==============================================================================
# DATA DIRECTORIES
# ==============================================================================
DATA_DIR=./data
KNOWLEDGE_BASE_DIR=./data/files/knowledge_base

# ==============================================================================
# PRIMARY LLM PROVIDER (openai, google, huggingface, llamacpp)
# Generic consolidated settings for all providers - fill in the applicable ones for your provider
# ==============================================================================
LLM_PROVIDER=openai
LLM_API_KEY=your_api_key_here
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
LLM_ENDPOINT_URL=
LLM_MODEL_PATH=
LLM_MODE=api
LLM_TIMEOUT=120
LLM_TASK=text-generation
LLM_CONTEXT_SIZE=4096
LLM_N_THREADS=4
LLM_N_BATCH=512

# ==============================================================================
# FALLBACK LLM (used when primary fails, optional)
# ==============================================================================
ENABLE_FALLBACK_LLM=false
FALLBACK_LLM_PROVIDER=openai
FALLBACK_LLM_API_KEY=your_api_key_here
FALLBACK_LLM_MODEL=gpt-4o-mini
FALLBACK_LLM_TEMPERATURE=0.5
FALLBACK_LLM_MAX_TOKENS=1000
FALLBACK_LLM_ENDPOINT_URL=
FALLBACK_LLM_MODEL_PATH=
FALLBACK_LLM_MODE=api
FALLBACK_LLM_TIMEOUT=120
FALLBACK_LLM_TASK=text-generation

# ==============================================================================
# INTERNAL LLM (for sensitive/high-security documents optional)
# ==============================================================================
ENABLE_INTERNAL_LLM=false
INTERNAL_LLM_PROVIDER=llamacpp
INTERNAL_LLM_API_KEY=
INTERNAL_LLM_MODEL=llama-3.1-8b-instruct
INTERNAL_LLM_TEMPERATURE=0.7
INTERNAL_LLM_MAX_TOKENS=1000
INTERNAL_LLM_MIN_SECURITY_LEVEL=4
INTERNAL_LLM_MODE=api
INTERNAL_LLM_ENDPOINT_URL=http://localhost:8080/v1
INTERNAL_LLM_TIMEOUT=120

# ==============================================================================
# CLASSIFIER/DECOMPOSER LLM (intent classification & query decomposition)
# ==============================================================================
ENABLE_LLM_CLASSIFIER=false
ENABLE_QUERY_DECOMPOSER=false
CLASSIFIER_LLM_PROVIDER=
CLASSIFIER_LLM_API_KEY=
CLASSIFIER_LLM_MODEL=
CLASSIFIER_LLM_ENDPOINT_URL=
CLASSIFIER_LLM_TIMEOUT=120

# ==============================================================================
# EMBEDDING PROVIDER (openai, google, huggingface, cohere)
# ==============================================================================
EMBEDDING_PROVIDER=huggingface
EMBEDDING_API_KEY=
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSIONS=
EMBEDDING_DEVICE=cpu
EMBEDDING_TASK_TYPE=RETRIEVAL_DOCUMENT
EMBEDDING_INPUT_TYPE=search_document

# ==============================================================================
# VECTOR DATABASE (faiss, chroma, qdrant, pinecone, weaviate, milvus)
# ==============================================================================
VECTOR_DB_PROVIDER=qdrant
ENABLE_HYBRID_SEARCH=false
VECTOR_STORE_COLLECTION_NAME=rag_fortress
VECTOR_STORE_PERSIST_DIRECTORY=./data/vector_store
VECTOR_DB_URL=
VECTOR_DB_API_KEY=
VECTOR_DB_HOST=localhost
VECTOR_DB_PORT=6333
VECTOR_DB_USERNAME=
VECTOR_DB_PASSWORD=
VECTOR_DB_PREFER_GRPC=false
VECTOR_DB_INDEX_NAME=rag_fortress
VECTOR_DB_CLASS_NAME=Document
VECTOR_DB_ENVIRONMENT=us-west1-gcp
VECTOR_DB_DENSE_VECTOR_NAME=dense
VECTOR_DB_SPARSE_VECTOR_NAME=sparse

# ==============================================================================
# DATABASE (postgresql, mysql, sqlite)
# ==============================================================================
DATABASE_PROVIDER=postgresql
DB_HOST=localhost
DB_PORT=5432
DB_USER=rag_fortress
DB_PASSWORD=your_secure_password
DB_NAME=rag_fortress
POSTGRES_SSL_MODE=prefer
MYSQL_CHARSET=utf8mb4
SQLITE_PATH=./data/rag_fortress.db
SQLITE_CHECK_SAME_THREAD=False
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30
DB_POOL_RECYCLE=3600
DB_ECHO=False

# ==============================================================================
# RAG CONFIGURATION
# ==============================================================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNK_INGESTION_BATCH_SIZE=1000
TOP_K=3
MAX_K=10
RETRIEVAL_SCORE_THRESHOLD=0.5

# ==============================================================================
# RERANKER CONFIGURATION Providers: huggingface (local), cohere (API), jina (API)
# ==============================================================================
ENABLE_RERANKER=true
RERANKER_PROVIDER=huggingface
RERANKER_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2
RERANKER_API_KEY=
RERANKER_SCORE_THRESHOLD=0.5

# ==============================================================================
# SECURITY
# ==============================================================================
SECRET_KEY=your_secret_key_here_change_in_production_at_least_32_characters_long
MASTER_ENCRYPTION_KEY=your_master_encryption_key_32_chars_minimum_for_aes_encryption
SETTINGS_ENCRYPTION_KEY=your_settings_encryption_key_32_chars_minimum_for_aes_encryption
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30            # Used for both JWT token and cookie expiration
REFRESH_TOKEN_EXPIRE_DAYS=7               # Used for both JWT token and cookie expiration
COOKIE_SECURE=true                        # Set to false for HTTP development
COOKIE_SAMESITE=lax                      # Options: "lax", "strict", "none" (use "none" for cross-origin)  
# Token expiry (minutes/days)
EMAIL_VERIFICATION_TOKEN_EXPIRE_MINUTES=120
PASSWORD_RESET_TOKEN_EXPIRE_MINUTES=60
INVITE_TOKEN_EXPIRE_DAYS=7 

# ==============================================================================
# CORS
# ==============================================================================
CORS_ORIGINS=["http://localhost:5173","http://localhost:3000"]
CORS_CREDENTIALS=True
CORS_METHODS=["GET", "POST", "PUT", "DELETE"]
CORS_HEADERS=["*"]

# ==============================================================================
# RATE LIMITING
# ==============================================================================
RATE_LIMIT_ENABLED=true
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000
CONVERSATION_RATE_LIMIT_PER_MINUTE=10
CONVERSATION_RATE_LIMIT_PER_HOUR=100
RATE_LIMIT_STORAGE=memory
RATE_LIMIT_REDIS_URL=redis://localhost:6379/1

# ==============================================================================
# CACHE (redis, memory)
# ==============================================================================
CACHE_BACKEND=redis
CACHE_ENABLED=true
CACHE_REDIS_URL=redis://localhost:6379/0
# TTL in seconds
CACHE_TTL_DEFAULT=300
CACHE_TTL_STATS=60
CACHE_TTL_CONFIG=3600
CACHE_TTL_USER_DATA=300
CACHE_TTL_SESSION=1800
CACHE_TTL_HISTORY=3600
ENABLE_CACHE_HISTORY_ENCRYPTION=false          # Conversation History Cache Encryption

# ==============================================================================
# SEMANTIC CACHE - Two-Tier System (Response + Context)
# Each tier works independently - enable the ones you need
# distance threshold: lower = more similar, higher = less similar
# ==============================================================================
# Global semantic cache settings
SEMANTIC_CACHE_INDEX_NAME=semantic_cache
SEMANTIC_CACHE_VECTOR_DIM=384
# Response-level caching (caches final LLM responses)
ENABLE_RESPONSE_CACHE=false
RESPONSE_CACHE_TTL_MINUTES=60
RESPONSE_CACHE_MAX_ENTRIES=3
RESPONSE_CACHE_DISTANCE_THRESHOLD=0.25
RESPONSE_CACHE_ENCRYPT=false
# Context-level caching (caches retrieved contexts before LLM)
ENABLE_CONTEXT_CACHE=false
CONTEXT_CACHE_TTL_MINUTES=120
CONTEXT_CACHE_MAX_ENTRIES=1
CONTEXT_CACHE_DISTANCE_THRESHOLD=0.1
CONTEXT_CACHE_ENCRYPT=false
# Vectorizer settings for semantic cache
# Options: use existing embedding model or separate one
REDISVL_USE_EXISTING_EMBEDDING=true
# { openai, huggingface, cohere }
REDISVL_PROVIDER=huggingface
REDISVL_API_KEY=your_api_key_here
REDISVL_MODEL=sentence-transformers/all-MiniLM-L6-v2
REDISVL_INPUT_TYPE=search_document

# ==============================================================================
# EMAIL
# ==============================================================================
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your_email@gmail.com
SMTP_PASSWORD=your_app_password_here
SMTP_FROM_EMAIL=noreply@ragfortress.com
SMTP_FROM_NAME=RAG Fortress
SMTP_USE_TLS=True
SMTP_USE_SSL=False

# ==============================================================================
# LOGGING
# ==============================================================================
LOG_LEVEL=INFO
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
LOG_FILE=logs/rag_fortress.log
LOG_MAX_BYTES=10485760
LOG_BACKUP_COUNT=5

# ==============================================================================
# LLM PROMPTS AND RETRIEVAL MESSAGES
# ==============================================================================
# Uncomment and set these to override the default prompts in prompt_settings.py
# RAG_SYSTEM_PROMPT=
# RETRIEVAL_NO_CONTEXT_MESSAGE=
# PARTIAL_CONTEXT_CLEARANCE_PROMPT=
# PARTIAL_CONTEXT_MISSING_PROMPT=
# CLASSIFIER_SYSTEM_PROMPT=
# CLASSIFIER_USER_PROMPT=
# DECOMPOSER_SYSTEM_PROMPT=
# RETRIEVAL_DEPT_BLOCKED_MESSAGE=
# RETRIEVAL_SECURITY_BLOCKED_MESSAGE=

# ==============================================================================
# DEFAULT ADMIN ACCOUNT
# ==============================================================================
ADMIN_USERNAME=admin
ADMIN_EMAIL=admin@ragfortress.com
ADMIN_PASSWORD=admin@RAGFortress123
ADMIN_FIRSTNAME=Admin
ADMIN_LASTNAME=User